{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499d7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f3681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VARIABLE FILE PATHS\n",
    "MKVarfile_path = r'C:\\Users\\gduln001\\Desktop\\WE 10.21\\VD_MK_824_MNSSHP_v11.xlsx'\n",
    "AKVarfile_path = r'C:\\Users\\gduln001\\Desktop\\WE 10.21\\VD_AK_819_v22.xlsx'\n",
    "STVarfile_path = r'C:\\Users\\gduln001\\Desktop\\WE 10.21\\VD_ST_921_EEH_v3.xlsx'\n",
    "ECVarfile_path = r'C:\\Users\\gduln001\\Desktop\\WE 10.21\\VD_EC_921_v23.xlsx'\n",
    "DSVarfile_path = r'C:\\Users\\gduln001\\Desktop\\WE 10.21\\VD_DS_23_TL_v23.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00296146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT OPERATING DAY NAME\n",
    "MKDayOperating = 'VD_MK_922_v21'\n",
    "AKDayOperating = 'VD_AK_819_v20'\n",
    "STDayOperating = 'VD_ST_921_EEH_v2'\n",
    "ECDayOperating = 'VD_EC_921_v21'\n",
    "DSDayOperating = 'VD_DS_23_TL_v21'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e64c027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXED FILE PATHS\n",
    "MKFixedfile_path = r'C:\\Users\\LeeT136\\Desktop\\WE 10.21\\Fixed_MK_SpringFY23v3.xlsx'\n",
    "AKFixedfile_path = r'C:\\Users\\LeeT136\\Desktop\\WE 10.21\\FixedST9AKSpringFY23 OP.xlsx'\n",
    "STFixedfile_path = r'C:\\Users\\LeeT136\\Desktop\\WE 10.21\\FixedST9AKSpringFY23 OP.xlsx'\n",
    "ECFixedfile_path = r'C:\\Users\\LeeT136\\Desktop\\WE 10.21\\Fixed_EC_SpringFY23_v2 OP.xlsx'\n",
    "DSFixedfile_path = r'C:\\Users\\LeeT136\\Desktop\\WE 10.21\\Fixed_DSSpringFY23v2 OP.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc5859bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Unsupported format, or corrupt file: Expected BOF record; found b'Line\\tCom'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#VARIABLE PATH DO NOT CHANGE\u001b[39;00m\n\u001b[0;32m      2\u001b[0m MK_OPERATING_DAY \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(MKVarfile_path, engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m AK_OPERATING_DAY \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(AKVarfile_path, engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlrd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m ST_OPERATING_DAY \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(STVarfile_path, engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m EC_OPERATING_DAY \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(ECVarfile_path, engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:482\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    481\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(io, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, engine\u001b[38;5;241m=\u001b[39mengine)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1695\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engines[engine](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_xlrd.py:35\u001b[0m, in \u001b[0;36mXlrdReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m     33\u001b[0m err_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall xlrd >= 1.0.0 for Excel support\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlrd\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra\u001b[38;5;241m=\u001b[39merr_msg)\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:545\u001b[0m, in \u001b[0;36mBaseExcelReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 545\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_workbook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_xlrd.py:48\u001b[0m, in \u001b[0;36mXlrdReader.load_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     47\u001b[0m     data \u001b[38;5;241m=\u001b[39m filepath_or_buffer\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m open_workbook(file_contents\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m open_workbook(filepath_or_buffer)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\xlrd\\__init__.py:172\u001b[0m, in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_format \u001b[38;5;129;01mand\u001b[39;00m file_format \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XLRDError(FILE_FORMAT_DESCRIPTIONS[file_format]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; not supported\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m bk \u001b[38;5;241m=\u001b[39m open_workbook_xls(\n\u001b[0;32m    173\u001b[0m     filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m    174\u001b[0m     logfile\u001b[38;5;241m=\u001b[39mlogfile,\n\u001b[0;32m    175\u001b[0m     verbosity\u001b[38;5;241m=\u001b[39mverbosity,\n\u001b[0;32m    176\u001b[0m     use_mmap\u001b[38;5;241m=\u001b[39muse_mmap,\n\u001b[0;32m    177\u001b[0m     file_contents\u001b[38;5;241m=\u001b[39mfile_contents,\n\u001b[0;32m    178\u001b[0m     encoding_override\u001b[38;5;241m=\u001b[39mencoding_override,\n\u001b[0;32m    179\u001b[0m     formatting_info\u001b[38;5;241m=\u001b[39mformatting_info,\n\u001b[0;32m    180\u001b[0m     on_demand\u001b[38;5;241m=\u001b[39mon_demand,\n\u001b[0;32m    181\u001b[0m     ragged_rows\u001b[38;5;241m=\u001b[39mragged_rows,\n\u001b[0;32m    182\u001b[0m     ignore_workbook_corruption\u001b[38;5;241m=\u001b[39mignore_workbook_corruption,\n\u001b[0;32m    183\u001b[0m )\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bk\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\xlrd\\book.py:79\u001b[0m, in \u001b[0;36mopen_workbook_xls\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[0;32m     77\u001b[0m t1 \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m     78\u001b[0m bk\u001b[38;5;241m.\u001b[39mload_time_stage_1 \u001b[38;5;241m=\u001b[39m t1 \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m---> 79\u001b[0m biff_version \u001b[38;5;241m=\u001b[39m bk\u001b[38;5;241m.\u001b[39mgetbof(XL_WORKBOOK_GLOBALS)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m biff_version:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XLRDError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt determine file\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms BIFF version\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\xlrd\\book.py:1284\u001b[0m, in \u001b[0;36mBook.getbof\u001b[1;34m(self, rqd_stream)\u001b[0m\n\u001b[0;32m   1282\u001b[0m     bof_error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected BOF record; met end of file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opcode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m bofcodes:\n\u001b[1;32m-> 1284\u001b[0m     bof_error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected BOF record; found \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem[savpos:savpos\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m8\u001b[39m])\n\u001b[0;32m   1285\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget2bytes()\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m==\u001b[39m MY_EOF:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\xlrd\\book.py:1278\u001b[0m, in \u001b[0;36mBook.getbof.<locals>.bof_error\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbof_error\u001b[39m(msg):\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XLRDError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnsupported format, or corrupt file: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m msg)\n",
      "\u001b[1;31mXLRDError\u001b[0m: Unsupported format, or corrupt file: Expected BOF record; found b'Line\\tCom'"
     ]
    }
   ],
   "source": [
    "#VARIABLE PATH DO NOT CHANGE\n",
    "MK_OPERATING_DAY = pd.read_excel(MKVarfile_path, engine = 'openpyxl')\n",
    "AK_OPERATING_DAY = pd.read_excel(AKVarfile_path, engine = 'xlrd')\n",
    "ST_OPERATING_DAY = pd.read_excel(STVarfile_path, engine = 'openpyxl')\n",
    "EC_OPERATING_DAY = pd.read_excel(ECVarfile_path, engine = 'openpyxl')\n",
    "DS_OPERATING_DAY = pd.read_excel(DSVarfile_path, engine = 'openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e149543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXED PATH DO NOT CHANGE\n",
    "MK_FIXED_WORK = pd.read_excel(MKFixedfile_path)\n",
    "AK_FIXED_WORK = pd.read_excel(AKFixedfile_path)\n",
    "ST_FIXED_WORK = pd.read_excel(STFixedfile_path)\n",
    "EC_FIXED_WORK = pd.read_excel(ECFixedfile_path)\n",
    "DS_FIXED_WORK = pd.read_excel(DSFixedfile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd46b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmk = MK_OPERATING_DAY\n",
    "dfak = AK_OPERATING_DAY\n",
    "dfst = ST_OPERATING_DAY\n",
    "dfec = EC_OPERATING_DAY\n",
    "dfds = DS_OPERATING_DAY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MK\n",
    "dfmk['Start Time'] = dfmk['Start Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "MK_FIXED_WORK['Start Time'] = MK_FIXED_WORK['Start Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "dfmk['End Time'] = dfmk['End Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "MK_FIXED_WORK['End Time'] = MK_FIXED_WORK['End Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "\n",
    "#AK\n",
    "dfak['Start Time'] = dfak['Start Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "AK_FIXED_WORK['Start Time'] = AK_FIXED_WORK['Start Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "dfak['End Time'] = dfak['End Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "AK_FIXED_WORK['End Time'] = AK_FIXED_WORK['End Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "\n",
    "#ST\n",
    "dfst['Start Time'] = dfst['Start Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "ST_FIXED_WORK['Start Time'] = ST_FIXED_WORK['Start Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "dfst['End Time'] = dfst['End Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "ST_FIXED_WORK['End Time'] = ST_FIXED_WORK['End Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "\n",
    "#EC\n",
    "dfec['Start Time'] = dfec['Start Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "EC_FIXED_WORK['Start Time'] = EC_FIXED_WORK['Start Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "dfec['End Time'] = dfec['End Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "EC_FIXED_WORK['End Time'] = EC_FIXED_WORK['End Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "\n",
    "#DS\n",
    "dfds['Start Time'] = dfds['Start Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "DS_FIXED_WORK['Start Time'] = DS_FIXED_WORK['Start Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "dfds['End Time'] = dfds['End Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n",
    "DS_FIXED_WORK['End Time'] = DS_FIXED_WORK['End Time'].apply(lambda x: dt.datetime(1900, 1, 1, x.hour, x.minute, x.second) + dt.timedelta(days=(1 if x.hour < 4 else 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MK\n",
    "dfmk['Start Time'] = pd.to_datetime(dfmk['Start Time'])\n",
    "dfmk['End Time'] = pd.to_datetime(dfmk['End Time'])\n",
    "dfmk['Headway'] = dfmk['End Time'] - dfmk['Start Time']\n",
    "dfmk['Headway'] = dfmk['Headway'].astype(str).str.split(' ').str[-1] \n",
    "\n",
    "MK_FIXED_WORK['Start Time'] = pd.to_datetime(MK_FIXED_WORK['Start Time'])\n",
    "MK_FIXED_WORK['End Time'] = pd.to_datetime(MK_FIXED_WORK['End Time'])\n",
    "MK_FIXED_WORK['Headway'] = MK_FIXED_WORK['End Time'] - MK_FIXED_WORK['Start Time']\n",
    "MK_FIXED_WORK['Headway'] = MK_FIXED_WORK['Headway'].astype(str).str.split(' ').str[-1] \n",
    "\n",
    "#AK\n",
    "dfak['Start Time'] = pd.to_datetime(dfak['Start Time'])\n",
    "dfak['End Time'] = pd.to_datetime(dfak['End Time'])\n",
    "dfak['Headway'] = dfak['End Time'] - dfak['Start Time']\n",
    "dfak['Headway'] = dfak['Headway'].astype(str).str.split(' ').str[-1] \n",
    "\n",
    "AK_FIXED_WORK['Start Time'] = pd.to_datetime(AK_FIXED_WORK['Start Time'])\n",
    "AK_FIXED_WORK['End Time'] = pd.to_datetime(AK_FIXED_WORK['End Time'])\n",
    "AK_FIXED_WORK['Headway'] = AK_FIXED_WORK['End Time'] - AK_FIXED_WORK['Start Time']\n",
    "AK_FIXED_WORK['Headway'] = AK_FIXED_WORK['Headway'].astype(str).str.split(' ').str[-1]\n",
    "\n",
    "#ST\n",
    "dfst['Start Time'] = pd.to_datetime(dfst['Start Time'])\n",
    "dfst['End Time'] = pd.to_datetime(dfst['End Time'])\n",
    "dfst['Headway'] = dfst['End Time'] - dfst['Start Time']\n",
    "dfst['Headway'] = dfst['Headway'].astype(str).str.split(' ').str[-1] \n",
    "\n",
    "ST_FIXED_WORK['Start Time'] = pd.to_datetime(ST_FIXED_WORK['Start Time'])\n",
    "ST_FIXED_WORK['End Time'] = pd.to_datetime(ST_FIXED_WORK['End Time'])\n",
    "ST_FIXED_WORK['Headway'] = ST_FIXED_WORK['End Time'] - ST_FIXED_WORK['Start Time']\n",
    "ST_FIXED_WORK['Headway'] = ST_FIXED_WORK['Headway'].astype(str).str.split(' ').str[-1] \n",
    "\n",
    "#EC\n",
    "dfec['Start Time'] = pd.to_datetime(dfec['Start Time'])\n",
    "dfec['End Time'] = pd.to_datetime(dfec['End Time'])\n",
    "dfec['Headway'] = dfec['End Time'] - dfec['Start Time']\n",
    "dfec['Headway'] = dfec['Headway'].astype(str).str.split(' ').str[-1] \n",
    "\n",
    "EC_FIXED_WORK['Start Time'] = pd.to_datetime(EC_FIXED_WORK['Start Time'])\n",
    "EC_FIXED_WORK['End Time'] = pd.to_datetime(EC_FIXED_WORK['End Time'])\n",
    "EC_FIXED_WORK['Headway'] = EC_FIXED_WORK['End Time'] - EC_FIXED_WORK['Start Time']\n",
    "EC_FIXED_WORK['Headway'] = EC_FIXED_WORK['Headway'].astype(str).str.split(' ').str[-1] \n",
    "\n",
    "#DS\n",
    "dfds['Start Time'] = pd.to_datetime(dfds['Start Time'])\n",
    "dfds['End Time'] = pd.to_datetime(dfds['End Time'])\n",
    "dfds['Headway'] = dfds['End Time'] - dfds['Start Time']\n",
    "dfds['Headway'] = dfds['Headway'].astype(str).str.split(' ').str[-1]\n",
    "\n",
    "DS_FIXED_WORK['Start Time'] = pd.to_datetime(DS_FIXED_WORK['Start Time'])\n",
    "DS_FIXED_WORK['End Time'] = pd.to_datetime(DS_FIXED_WORK['End Time'])\n",
    "DS_FIXED_WORK['Headway'] = DS_FIXED_WORK['End Time'] - DS_FIXED_WORK['Start Time']\n",
    "DS_FIXED_WORK['Headway'] = DS_FIXED_WORK['Headway'].astype(str).str.split(' ').str[-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a0476",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedMK = pd.concat([dfmk, MK_FIXED_WORK], ignore_index=True)\n",
    "groupedAK = pd.concat([dfak, AK_FIXED_WORK], ignore_index=True)\n",
    "groupedST = pd.concat([dfst, ST_FIXED_WORK], ignore_index=True)\n",
    "groupedEC = pd.concat([dfec, EC_FIXED_WORK], ignore_index=True)\n",
    "groupedDS = pd.concat([dfds, DS_FIXED_WORK], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8e9260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MK\n",
    "MKpattern_mapping = {\n",
    "    'SO_MK' : 'SO_MK/WE_SO_MK',\n",
    "    'WE_SO_MK' : 'SO_MK/WE_SO_MK',\n",
    "    'TN_MK': 'TN_MK/MT_TN_MK',\n",
    "    'MT_TN_MK': 'TN_MK/MT_TN_MK',\n",
    "    'AB_MK': 'AB_MK/JA_AB_MK',\n",
    "    'JA_AB_MK': 'AB_MK/JA_AB_MK',\n",
    "    'EL_MK' : 'EL_MK/CA_EL_MK',\n",
    "    'CA_EL_MK' : 'EL_MK/CA_EL_MK',\n",
    "    'HH_MK' : 'HH_MK/PN_HH_MK',\n",
    "    'PN_HH_MK' : 'HH_MK/PN_HH_MK',\n",
    "    'SP_MK' : 'SP_MK/GS_SP_MK',\n",
    "    'GS_SP_MK' : 'SP_MK/GS_SP_MK' \n",
    "}\n",
    "\n",
    "\n",
    "groupedMK['Pattern'] = groupedMK['Pattern'].replace(MKpattern_mapping)\n",
    "\n",
    "#AK\n",
    "AKpattern_mapping = {\n",
    "    'BC_AK' : 'BC_AK/YC_BC_AK',\n",
    "    'YC_BC_AK' : 'BC_AK/YC_BC_AK',\n",
    "    'RS-S_AK': 'RS-S_AK/RS-WNES-AK',\n",
    "    'PL_AK': 'AK_PL_GF',\n",
    "    'GF_AK': 'AK_PL_GF',\n",
    "    'RS-WNES-AK': 'RS-S_AK/RS-WNES-AK',\n",
    "    'CB-TN_AK': 'CB-TN_AK/MT_TN_AK',\n",
    "    'MT_TN_AK': 'CB-TN_AK/MT_TN_AK',\n",
    "    'CB-AB_AK' : 'CB-AB_AK/JA_AB_AK',\n",
    "    'JA_AB_AK' : 'CB-AB_AK/JA_AB_AK',\n",
    "    'EL_AK' : 'EL_AK/CA_EL_AK',\n",
    "    'CA_EL_AK' : 'EL_AK/CA_EL_AK',\n",
    "    'KW-HH_AK' : 'KW-HH_AK/PN_HH_AK',\n",
    "    'PN_HH_AK' : 'KW-HH_AK/PN_HH_AK',\n",
    "    'SS-SP_AK' : 'SS-SP_AK/GS_SP_AK',\n",
    "    'GS_SP_AK' : 'SS-SP_AK/GS_SP_AK'    \n",
    "}\n",
    "\n",
    "groupedAK['Pattern'] = groupedAK['Pattern'].replace(AKpattern_mapping)\n",
    "\n",
    "\n",
    "#ST\n",
    "STpattern_mapping = {\n",
    "    'GF_ST' : 'ST_PL_GF',\n",
    "    'PL_ST' : 'ST_PL_GF',\n",
    "    'SO_ST' : 'SO_ST/WE_SO_ST',\n",
    "    'WE_SO_ST' : 'SO_ST/WE_SO_ST',\n",
    "    'EL_ST' : 'EL_ST/CT_CA_EL_ST',\n",
    "    'CT_CA_EL_ST' : 'EL_ST/CT_CA_EL_ST',\n",
    "    'HH_ST' : 'HH_ST/PN_HH_ST',\n",
    "    'PN_HH_ST' : 'HH_ST/PN_HH_ST',\n",
    "    'SP_ST' : 'SP_ST/GS_SP_ST',\n",
    "    'GS_SP_ST' : 'SP_ST/GS_SP_ST',      \n",
    "}\n",
    "\n",
    "groupedST['Pattern'] = groupedST['Pattern'].replace(STpattern_mapping)\n",
    "\n",
    "#EC\n",
    "ECpattern_mapping = {\n",
    "    'SO_EC' : 'SO_EC/WE_SO_EC',\n",
    "    'WE_SO_EC' : 'SO_EC/WE_SO_EC',\n",
    "    'EL_EC' : 'EL_EC/CT_RN_CA_EL_EC',\n",
    "    'CT_RN_CA_EL_EC' : 'EL_EC/CT_RN_CA_EL_EC',\n",
    "    'HH_EC' : 'HH_EC/PN_HH_EC',\n",
    "    'PN_HH_EC' : 'HH_EC/PN_HH_EC',\n",
    "    'SP_EC' : 'SP_EC/GS_SP_EC',\n",
    "    'GS_SP_EC' : 'SP_EC/GS_SP_EC'   \n",
    "}\n",
    "\n",
    "groupedEC['Pattern'] = groupedEC['Pattern'].replace(ECpattern_mapping)\n",
    "\n",
    "#DS\n",
    "DSpattern_mapping = {\n",
    "    'KI_DS' : 'KI_DS/JM_KI_DS',\n",
    "    'JM_KI_DS' : 'KI_DS/JM_KI_DS',\n",
    "    'GF_DS' : 'GF_DS/PL_GF_DS',\n",
    "    'PL_GF_DS' : 'GF_DS/PL_GF_DS',\n",
    "    'CO_DS' : 'CO_DS/WL_CO_DS',\n",
    "    'WL_CO_DS' : 'CO_DS/WL_CO_DS',\n",
    "    'BW_DS' : 'BW_DS/YC_BC_BW_DS',\n",
    "    'YC_BC_BW_DS' : 'BW_DS/YC_BC_BW_DS',\n",
    "    'AB_DS' : 'AB_DS/MT_RO_AB_DS',\n",
    "    'MT_RO_AB_DS' : 'AB_DS/MT_RO_AB_DS',\n",
    "    'CA_DS' : 'CA_DS/EL_CT_CA_DS',\n",
    "    'EL_CT_CA_DS' : 'CA_DS/EL_CT_CA_DS',\n",
    "    'MR_DS' : 'MR_DS/HH_PI_SP_TP_MR_DS',\n",
    "    'HH_PI_SP_TP_MR_DS' : 'MR_DS/HH_PI_SP_TP_MR_DS',\n",
    "    'CP_DS' : 'CP_DS/SP_GD_CS_PD_CP_DS',\n",
    "    'SP_GD_CS_PD_CP_DS' : 'CP_DS/SP_GD_CS_PD_CP_DS'\n",
    "}\n",
    "\n",
    "groupedDS['Pattern'] = groupedDS['Pattern'].replace(DSpattern_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MK\n",
    "groupedMK['Start Time'] = pd.to_datetime(groupedMK['Start Time'])\n",
    "groupedMK['End Time'] = pd.to_datetime(groupedMK['End Time'])\n",
    "groupedMK['Headway'] = (groupedMK['End Time'] - groupedMK['Start Time']).dt.total_seconds() / 60  # Convert to minutes\n",
    "groupedMK = groupedMK.groupby(['Pattern', 'Start Time',]).agg({'End Time': 'first', 'Headway': 'first', 'Operating Day': 'first'}).reset_index()\n",
    "\n",
    "#AK\n",
    "groupedAK['Start Time'] = pd.to_datetime(groupedAK['Start Time'])\n",
    "groupedAK['End Time'] = pd.to_datetime(groupedAK['End Time'])\n",
    "groupedAK['Headway'] = (groupedAK['End Time'] - groupedAK['Start Time']).dt.total_seconds() / 60  # Convert to minutes\n",
    "groupedAK = groupedAK.groupby(['Pattern', 'Start Time',]).agg({'End Time': 'first', 'Headway': 'first', 'Operating Day': 'first'}).reset_index()\n",
    "\n",
    "#ST\n",
    "groupedST['Start Time'] = pd.to_datetime(groupedST['Start Time'])\n",
    "groupedST['End Time'] = pd.to_datetime(groupedST['End Time'])\n",
    "groupedST['Headway'] = (groupedST['End Time'] - groupedST['Start Time']).dt.total_seconds() / 60  # Convert to minutes\n",
    "groupedST = groupedST.groupby(['Pattern', 'Start Time',]).agg({'End Time': 'first', 'Headway': 'first', 'Operating Day': 'first'}).reset_index()\n",
    "\n",
    "#EC\n",
    "groupedEC['Start Time'] = pd.to_datetime(groupedEC['Start Time'])\n",
    "groupedEC['End Time'] = pd.to_datetime(groupedEC['End Time'])\n",
    "groupedEC['Headway'] = (groupedEC['End Time'] - groupedEC['Start Time']).dt.total_seconds() / 60  # Convert to minutes\n",
    "groupedEC = groupedEC.groupby(['Pattern', 'Start Time',]).agg({'End Time': 'first', 'Headway': 'first', 'Operating Day': 'first'}).reset_index()\n",
    "\n",
    "#DS\n",
    "groupedDS['Start Time'] = pd.to_datetime(groupedDS['Start Time'])\n",
    "groupedDS['End Time'] = pd.to_datetime(groupedDS['End Time'])\n",
    "groupedDS['Headway'] = (groupedDS['End Time'] - groupedDS['Start Time']).dt.total_seconds() / 60  # Convert to minutes\n",
    "groupedDS = groupedDS.groupby(['Pattern', 'Start Time',]).agg({'End Time': 'first', 'Headway': 'first', 'Operating Day': 'first'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8cd2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MK\n",
    "sortedMK = groupedMK.sort_values(by=['Pattern', 'Start Time'])\n",
    "sortedMK['Timestamp'] = sortedMK['Start Time'].dt.floor('H')\n",
    "sortedMK['BusTime'] = sortedMK.groupby(['Pattern', 'Timestamp'])['Start Time'].diff().dt.total_seconds() / 60\n",
    "sortedMK['Start Time'] = pd.to_datetime(sortedMK['Start Time'])\n",
    "sortedMK['Pattern'] = sortedMK['Pattern'].str.strip()\n",
    "sortedMK['Hour'] = sortedMK['Start Time'].dt.hour\n",
    "MKraw_pattern_hour_avg = sortedMK.groupby(['Pattern', 'Hour'])['BusTime'].mean().unstack()\n",
    "\n",
    "#AK\n",
    "sortedAK = groupedAK.sort_values(by=['Pattern', 'Start Time'])\n",
    "sortedAK['Timestamp'] = sortedAK['Start Time'].dt.floor('H')\n",
    "sortedAK['BusTime'] = sortedAK.groupby(['Pattern', 'Timestamp'])['Start Time'].diff().dt.total_seconds() / 60\n",
    "sortedAK['Start Time'] = pd.to_datetime(sortedAK['Start Time'])\n",
    "sortedAK['Pattern'] = sortedAK['Pattern'].str.strip()\n",
    "sortedAK['Hour'] = sortedAK['Start Time'].dt.hour\n",
    "AKraw_pattern_hour_avg = sortedAK.groupby(['Pattern', 'Hour'])['BusTime'].mean().unstack()\n",
    "\n",
    "#ST\n",
    "sortedST = groupedST.sort_values(by=['Pattern', 'Start Time'])\n",
    "sortedST['Timestamp'] = sortedST['Start Time'].dt.floor('H')\n",
    "sortedST['BusTime'] = sortedST.groupby(['Pattern', 'Timestamp'])['Start Time'].diff().dt.total_seconds() / 60\n",
    "sortedST['Start Time'] = pd.to_datetime(sortedST['Start Time'])\n",
    "sortedST['Pattern'] = sortedST['Pattern'].str.strip()\n",
    "sortedST['Hour'] = sortedST['Start Time'].dt.hour\n",
    "STraw_pattern_hour_avg = sortedST.groupby(['Pattern', 'Hour'])['BusTime'].mean().unstack()\n",
    "\n",
    "#EC\n",
    "\n",
    "sortedEC = groupedEC.sort_values(by=['Pattern', 'Start Time'])\n",
    "sortedEC['Timestamp'] = sortedEC['Start Time'].dt.floor('H')\n",
    "sortedEC['BusTime'] = sortedEC.groupby(['Pattern', 'Timestamp'])['Start Time'].diff().dt.total_seconds() / 60\n",
    "sortedEC['Start Time'] = pd.to_datetime(sortedEC['Start Time'])\n",
    "sortedEC['Pattern'] = sortedEC['Pattern'].str.strip()\n",
    "sortedEC['Hour'] = sortedEC['Start Time'].dt.hour\n",
    "ECraw_pattern_hour_avg = sortedEC.groupby(['Pattern', 'Hour'])['BusTime'].mean().unstack()\n",
    "\n",
    "\n",
    "#DS\n",
    "sortedDS = groupedDS.sort_values(by=['Pattern', 'Start Time'])\n",
    "sortedDS['Timestamp'] = sortedDS['Start Time'].dt.floor('H')\n",
    "sortedDS['BusTime'] = sortedDS.groupby(['Pattern', 'Timestamp'])['Start Time'].diff().dt.total_seconds() / 60\n",
    "sortedDS['Start Time'] = pd.to_datetime(sortedDS['Start Time'])\n",
    "sortedDS['Pattern'] = sortedDS['Pattern'].str.strip()\n",
    "sortedDS['Hour'] = sortedDS['Start Time'].dt.hour\n",
    "DSraw_pattern_hour_avg = sortedDS.groupby(['Pattern', 'Hour'])['BusTime'].mean().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MK\n",
    "sortedMK['Start Time'] = pd.to_datetime(sortedMK['Start Time'])\n",
    "# Remove leading/trailing spaces from 'Pattern' column\n",
    "sortedMK['Pattern'] = sortedMK['Pattern'].str.strip()\n",
    "# Extract 'Hour' from 'Start Time'\n",
    "sortedMK['Hour'] = sortedMK['Start Time'].dt.hour\n",
    "# Calculate average 'Headway' grouped by 'Pattern' and 'Hour'\n",
    "MKraw_pattern_hour_avg = sortedMK.groupby(['Pattern', 'Hour'])['BusTime'].mean().unstack()\n",
    "UseMKdf = pd.DataFrame(MKraw_pattern_hour_avg)\n",
    "\n",
    "#AK\n",
    "sortedAK['Start Time'] = pd.to_datetime(sortedAK['Start Time'])\n",
    "# Remove leading/trailing spaces from 'Pattern' column\n",
    "sortedAK['Pattern'] = sortedAK['Pattern'].str.strip()\n",
    "# Extract 'Hour' from 'Start Time'\n",
    "sortedAK['Hour'] = sortedAK['Start Time'].dt.hour\n",
    "# Calculate average 'Headway' grouped by 'Pattern' and 'Hour'\n",
    "AKraw_pattern_hour_avg = sortedAK.groupby(['Pattern', 'Hour'])['BusTime'].mean().unstack()\n",
    "UseAKdf = pd.DataFrame(AKraw_pattern_hour_avg)\n",
    "\n",
    "#ST\n",
    "sortedST['Start Time'] = pd.to_datetime(sortedST['Start Time'])\n",
    "# Remove leading/trailing spaces from 'Pattern' column\n",
    "sortedST['Pattern'] = sortedST['Pattern'].str.strip()\n",
    "# Extract 'Hour' from 'Start Time'\n",
    "sortedST['Hour'] = sortedST['Start Time'].dt.hour\n",
    "# Calculate average 'Headway' grouped by 'Pattern' and 'Hour'\n",
    "STraw_pattern_hour_avg = sortedST.groupby(['Pattern', 'Hour'])['BusTime'].mean().unstack()\n",
    "UseSTdf = pd.DataFrame(STraw_pattern_hour_avg)\n",
    "\n",
    "#EC\n",
    "sortedEC['Start Time'] = pd.to_datetime(sortedEC['Start Time'])\n",
    "# Remove leading/trailing spaces from 'Pattern' column\n",
    "sortedEC['Pattern'] = sortedEC['Pattern'].str.strip()\n",
    "# Extract 'Hour' from 'Start Time'\n",
    "sortedEC['Hour'] = sortedEC['Start Time'].dt.hour\n",
    "# Calculate average 'Headway' grouped by 'Pattern' and 'Hour'\n",
    "ECraw_pattern_hour_avg = sortedEC.groupby(['Pattern', 'Hour'])['BusTime'].mean().unstack()\n",
    "UseECdf = pd.DataFrame(ECraw_pattern_hour_avg)\n",
    "\n",
    "#DS\n",
    "sortedDS['Start Time'] = pd.to_datetime(sortedDS['Start Time'])\n",
    "# Remove leading/trailing spaces from 'Pattern' column\n",
    "sortedDS['Pattern'] = sortedDS['Pattern'].str.strip()\n",
    "# Extract 'Hour' from 'Start Time'\n",
    "sortedDS['Hour'] = sortedDS['Start Time'].dt.hour\n",
    "# Calculate average 'Headway' grouped by 'Pattern' and 'Hour'\n",
    "DSraw_pattern_hour_avg = sortedDS.groupby(['Pattern', 'Hour'])['BusTime'].mean().unstack()\n",
    "UseDSdf = pd.DataFrame(DSraw_pattern_hour_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MK\n",
    "MKhour_counts = sortedMK.groupby(['Pattern', 'Hour'])['Start Time'].count().unstack()\n",
    "MKis_one_route_hour = MKhour_counts == 1\n",
    "\n",
    "for pattern, hour in MKis_one_route_hour[MKis_one_route_hour].stack().index:\n",
    "    MKraw_pattern_hour_avg.at[pattern, hour] = sortedMK.loc[(sortedMK['Pattern'] == pattern) & (sortedMK['Hour'] == hour), 'Start Time'].iloc[0]\n",
    "\n",
    "#AK\n",
    "\n",
    "AKhour_counts = sortedAK.groupby(['Pattern', 'Hour'])['Start Time'].count().unstack()\n",
    "AKis_one_route_hour = AKhour_counts == 1\n",
    "\n",
    "for pattern, hour in AKis_one_route_hour[AKis_one_route_hour].stack().index:\n",
    "    AKraw_pattern_hour_avg.at[pattern, hour] = sortedAK.loc[(sortedAK['Pattern'] == pattern) & (sortedAK['Hour'] == hour), 'Start Time'].iloc[0]\n",
    "\n",
    "#ST\n",
    "SThour_counts = sortedST.groupby(['Pattern', 'Hour'])['Start Time'].count().unstack()\n",
    "STis_one_route_hour = SThour_counts == 1\n",
    "\n",
    "for pattern, hour in STis_one_route_hour[STis_one_route_hour].stack().index:\n",
    "    STraw_pattern_hour_avg.at[pattern, hour] = sortedST.loc[(sortedST['Pattern'] == pattern) & (sortedST['Hour'] == hour), 'Start Time'].iloc[0]\n",
    "\n",
    "#EC \n",
    "EChour_counts = sortedEC.groupby(['Pattern', 'Hour'])['Start Time'].count().unstack()\n",
    "ECis_one_route_hour = EChour_counts == 1\n",
    "\n",
    "for pattern, hour in ECis_one_route_hour[ECis_one_route_hour].stack().index:\n",
    "    ECraw_pattern_hour_avg.at[pattern, hour] = sortedEC.loc[(sortedEC['Pattern'] == pattern) & (sortedEC['Hour'] == hour), 'Start Time'].iloc[0]\n",
    "    \n",
    "    \n",
    "#DS\n",
    "DShour_counts = sortedDS.groupby(['Pattern', 'Hour'])['Start Time'].count().unstack()\n",
    "DSis_one_route_hour = DShour_counts == 1\n",
    "\n",
    "for pattern, hour in DSis_one_route_hour[DSis_one_route_hour].stack().index:\n",
    "    DSraw_pattern_hour_avg.at[pattern, hour] = sortedDS.loc[(sortedDS['Pattern'] == pattern) & (sortedDS['Hour'] == hour), 'Start Time'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3176f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "MKam_patterns = [\n",
    "    \"\", \n",
    "    \"KI_MK\",\n",
    "    \"JM_MK\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"WL_MK\",\n",
    "    \"\",\n",
    "    \"FW-SE_MK\",\n",
    "    \"\",\n",
    "    \"YC_MK\",\n",
    "    \"BC_MK\",\n",
    "    \"BW_MK\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"RV_MK\",\n",
    "    \"\",\n",
    "    \"SO_MK/WE_SO_MK\",\n",
    "    \"FQ_MK\",\n",
    "    \"\",\n",
    "    \"TN_MK/MT_TN_MK\",\n",
    "    \"AB_MK/JA_AB_MK\",\n",
    "    \"EL_MK/CA_EL_MK\",\n",
    "    \"HH_MK/PN_HH_MK\",\n",
    "    \"SP_MK/GS_SP_MK\",\n",
    "    \"\",\n",
    "    \"AS_MK\",\n",
    "    \"AM_MK\",\n",
    "    \"AV_MK\",\n",
    "    \"PC_MK\",\n",
    "    \"AR_MK\",\n",
    "]\n",
    "\n",
    "# Permanent PM Patterns\n",
    "MKpm_patterns = [\n",
    "     \"MK_KI_JM\", \n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"MK_WL_SE_NEW\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"MK_YC_BC\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"MK_BW\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"MK_RV\",\n",
    "    \"\",\n",
    "    \"MK_EA_SO\",\n",
    "    \"MK_FQ\",\n",
    "    \"MK_MT_RO_TN_AB\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"MK_CA_EL\",\n",
    "    \"MK_PN_HH\",\n",
    "    \"MK_GS_SP\",\n",
    "    \"\",\n",
    "    \"MK_AS\",\n",
    "    \"MK_AM\",\n",
    "    \"MK_AV\",\n",
    "    \"MK_PC\",\n",
    "    \"MK_AR\",\n",
    "]\n",
    "\n",
    "\n",
    "MKpermanent_times = [\n",
    "    \"5:00\", \"6:00\", \"7:00\", \"8:00\", \"9:00\", \"10:00\", \"11:00\", \"12:00\",\n",
    "    \"13:00\", \"14:00\", \"15:00\", \"16:00\", \"17:00\", \"18:00\", \"19:00\",\n",
    "    \"20:00\", \"21:00\", \"22:00\", \"23:00\", \"24:00\", \"25:00\", \"26:00\",\n",
    "    \"27:00\"\n",
    "]\n",
    "\n",
    "\n",
    "MKdata = {\n",
    "    \"OperatingDay\": [],\n",
    "    \"Park\": [],\n",
    "    \"AM Pattern\": [],\n",
    "    \"PM Pattern\": []\n",
    "}\n",
    "\n",
    "for time in MKpermanent_times:\n",
    "    MKdata[time] = []\n",
    "    \n",
    "# Add AM and PM Patterns\n",
    "for am_pattern, pm_pattern in zip(MKam_patterns, MKpm_patterns):\n",
    "    MKdata[\"OperatingDay\"].append(MKDayOperating)\n",
    "    MKdata[\"Park\"].append(\"MK\")\n",
    "    MKdata[\"AM Pattern\"].append(am_pattern)\n",
    "    MKdata[\"PM Pattern\"].append(pm_pattern)\n",
    "    \n",
    "    for _ in MKpermanent_times:\n",
    "        MKdata[_].append(\"\")\n",
    "# Create DataFrame\n",
    "MKdf = pd.DataFrame(MKdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMcolumn_time_mapping = {\n",
    "    5: \"5:00\",\n",
    "    6: \"6:00\",\n",
    "    7: \"7:00\",\n",
    "    8: \"8:00\",\n",
    "    9: \"9:00\",\n",
    "    10: \"10:00\", \n",
    "}\n",
    "\n",
    "PMcolumn_time_mapping = {\n",
    "    0: \"24:00\",\n",
    "    1: \"25:00\",\n",
    "    2: \"26:00\",\n",
    "    3: \"27:00\",\n",
    "    11: \"11:00\",\n",
    "    12: \"12:00\",\n",
    "    13: \"13:00\",\n",
    "    14: \"14:00\",\n",
    "    15: \"15:00\",\n",
    "    16: \"16:00\",\n",
    "    17: \"17:00\",\n",
    "    18: \"18:00\",\n",
    "    19: \"19:00\",\n",
    "    20: \"20:00\",\n",
    "    21: \"21:00\",\n",
    "    22: \"22:00\",\n",
    "    23: \"23:00\"\n",
    "}\n",
    "\n",
    "column_time_mapping = {\n",
    "    0: \"24:00\",\n",
    "    1: \"25:00\",\n",
    "    2: \"26:00\",\n",
    "    3: \"27:00\",\n",
    "    5: \"5:00\",\n",
    "    6: \"6:00\",\n",
    "    7: \"7:00\",\n",
    "    8: \"8:00\",\n",
    "    9: \"9:00\",\n",
    "    10: \"10:00\",\n",
    "    11: \"11:00\",\n",
    "    12: \"12:00\",\n",
    "    13: \"13:00\",\n",
    "    14: \"14:00\",\n",
    "    15: \"15:00\",\n",
    "    16: \"16:00\",\n",
    "    17: \"17:00\",\n",
    "    18: \"18:00\",\n",
    "    19: \"19:00\",\n",
    "    20: \"20:00\",\n",
    "    21: \"21:00\",\n",
    "    22: \"22:00\",\n",
    "    23: \"23:00\"\n",
    "}\n",
    "\n",
    "#'MK_KI_JM' \n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_KI_JM']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[0, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[0, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[0, time_label] = None\n",
    "        \n",
    "#'KI_MK'        \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['KI_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[1, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[1, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[1, time_label] = None\n",
    "        \n",
    "#'JM_MK'    \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['JM_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[2, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[2, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[2, time_label] = None\n",
    "        \n",
    "#'MK_WL_SE_NEW'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_WL_SE_NEW']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[5, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[5, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[5, time_label] = None\n",
    "        \n",
    "#'WL_MK'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['WL_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[6, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[6, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[6, time_label] = None\n",
    "        \n",
    "#'FW-SE_MK'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['FW-SE_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[8, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[8, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[8, time_label] = None\n",
    "        \n",
    "#'MK_YC_BC'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_YC_BC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[9, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[9, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[9, time_label] = None\n",
    "        \n",
    "#'YC_MK'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['YC_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[10, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[10, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[10, time_label] = None\n",
    "        \n",
    "#'BC_MK'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['BC_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[11, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[11, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[11, time_label] = None\n",
    "        \n",
    "#'BW_MK', 'MK_BW'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['BW_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[12, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[12, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[12, time_label] = None\n",
    "        \n",
    "#'BW_MK', 'MK_BW'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_BW']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[12, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[12, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[12, time_label] = None\n",
    "        \n",
    "#'RV_MK', 'MK_RV'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['RV_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[15, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[15, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[15, time_label] = None\n",
    "        \n",
    "#'RV_MK', 'MK_RV'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_RV']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[15, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[15, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[15, time_label] = None\n",
    "        \n",
    "#'SO_MK', 'WE_SO_MK', 'MK_EA_SO'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['SO_MK/WE_SO_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[17, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[17, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[17, time_label] = None\n",
    "\n",
    "#'SO_MK', 'WE_SO_MK', 'MK_EA_SO'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_EA_SO']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[17, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[17, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[17, time_label] = None\n",
    "        \n",
    "#'FQ_MK', 'MK_FQ'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['FQ_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[18, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[18, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[18, time_label] = None\n",
    "        \n",
    "#'FQ_MK', 'MK_FQ'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_FQ']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[18, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[18, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[18, time_label] = None\n",
    "        \n",
    "#'MK_MT_RO_TN_AB'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_MT_RO_TN_AB']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[19, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[19, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[19, time_label] = None\n",
    "        \n",
    "#'TN_MK', 'MT_TN_MK'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['TN_MK/MT_TN_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[20, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[20, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[20, time_label] = None\n",
    "        \n",
    "#'AB_MK', 'JA_AB_MK'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['AB_MK/JA_AB_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[21, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[21, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[21, time_label] = None\n",
    "        \n",
    "#'EL_MK', 'CA_EL_MK', 'MK_CA_EL'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['EL_MK/CA_EL_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[22, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[22, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[22, time_label] = None\n",
    "        \n",
    "#'EL_MK', 'CA_EL_MK', 'MK_CA_EL'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_CA_EL']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[22, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[22, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[22, time_label] = None\n",
    "        \n",
    "#'HH_MK', 'PN_HH_MK', 'MK_PN_HH'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['HH_MK/PN_HH_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[23, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[23, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[23, time_label] = None\n",
    "        \n",
    "        \n",
    "#'HH_MK', 'PN_HH_MK', 'MK_PN_HH'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_PN_HH']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[23, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[23, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[23, time_label] = None\n",
    "        \n",
    "#'SP_MK', 'GS_SP_MK', 'MK_GS_SP'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['SP_MK/GS_SP_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[24, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[24, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[24, time_label] = None\n",
    "\n",
    "        #'SP_MK', 'GS_SP_MK', 'MK_GS_SP'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_GS_SP']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[24, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[24, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[24, time_label] = None\n",
    "        \n",
    "#'AS_MK', 'MK_AS'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['AS_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[26, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[26, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[26, time_label] = None\n",
    "\n",
    "#'AS_MK', 'MK_AS'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_AS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[26, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[26, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[26, time_label] = None\n",
    "        \n",
    "#'AM_MK', 'MK_AM'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['AM_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[27, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[27, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[27, time_label] = None\n",
    "        \n",
    "#'AM_MK', 'MK_AM'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_AM']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[27, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[27, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[27, time_label] = None\n",
    "        \n",
    "#'AV_MK', 'MK_AV'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['AV_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[28, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[28, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[28, time_label] = None\n",
    "        \n",
    "#'AV_MK', 'MK_AV'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_AV']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[28, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[28, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[28, time_label] = None\n",
    "        \n",
    "#'PC_MK', 'MK_PC'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['PC_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[29, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[29, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[29, time_label] = None\n",
    "        \n",
    "#'PC_MK', 'MK_PC'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_PC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[29, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[29, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[29, time_label] = None\n",
    "        \n",
    "#'AR_MK', 'MK_AR'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['AR_MK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[30, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[30, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[30, time_label] = None\n",
    "        \n",
    "#'AR_MK', 'MK_AR'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseMKdf.columns:\n",
    "        values = [UseMKdf.loc[row, column_number] for row in ['MK_AR']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            MKdf.loc[30, time_label] = min_value\n",
    "        else:\n",
    "            MKdf.loc[30, time_label] = None\n",
    "    else:\n",
    "        MKdf.loc[30, time_label] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f58c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AKam_patterns = [\n",
    "    \"\", \n",
    "    \"KI_AK\",\n",
    "    \"JM_AK\",\n",
    "    \"AK_PL_GF\",\n",
    "    \"PL_AK\",\n",
    "    \"GF_AK\",\n",
    "    \"\",\n",
    "    \"WL_AK\",\n",
    "    \"CO_AK\",\n",
    "    \"FW-OP_AK\",\n",
    "    \"\",\n",
    "    \"BC_AK/YC_BC_AK\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"BW_AK\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"RV_AK\",\n",
    "    \"\",\n",
    "    \"RS-S_AK/RS-WNES-AK\",\n",
    "    \"FQ_AK\",\n",
    "    \"\",\n",
    "    \"CB-TN_AK/MT_TN_AK\",\n",
    "    \"CB-AB_AK/JA_AB_AK\",\n",
    "    \"EL_AK/CA_EL_AK\",\n",
    "    \"KW-HH_AK/PN_HH_AK\",\n",
    "    \"SS-SP_AK/GS_SP_AK\",\n",
    "    \"\",\n",
    "    \"AS_AK\",\n",
    "    \"AM_AK\",\n",
    "    \"AV_AK\",\n",
    "    \"PC_AK\",\n",
    "    \"AR_AK\"\n",
    "]\n",
    "\n",
    "# Permanent PM Patterns\n",
    "AKpm_patterns = [\n",
    "    \"AK_KI_JM\", \n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"AK_PL_GF\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"AK_WL_CO\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"AK_FW-OP\",\n",
    "    \"AK_YC_BC_BW\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"AK_RV\",\n",
    "    \"\",\n",
    "    \"AK_WE_NO_EA_SO\",\n",
    "    \"AK_FQ\",\n",
    "    \"AK_JA_MT_RO_TN\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"AK_CA_EL\",\n",
    "    \"AK_PN_SP_TP_MR_HH\",\n",
    "    \"AK_SS\",\n",
    "    \"\",\n",
    "    \"AK_AS\",\n",
    "    \"AK_AM\",\n",
    "    \"AK_AV\",\n",
    "    \"AK_PC\",\n",
    "    \"AK_AR\"\n",
    "]\n",
    "\n",
    "\n",
    "AKpermanent_times = [\n",
    "    \"5:00\", \"6:00\", \"7:00\", \"8:00\", \"9:00\", \"10:00\", \"11:00\", \"12:00\",\n",
    "    \"13:00\", \"14:00\", \"15:00\", \"16:00\", \"17:00\", \"18:00\", \"19:00\",\n",
    "    \"20:00\", \"21:00\", \"22:00\", \"23:00\", \"24:00\", \"25:00\", \"26:00\",\n",
    "    \"27:00\"\n",
    "]\n",
    "\n",
    "\n",
    "AKdata = {\n",
    "    \"OperatingDay\": [],\n",
    "    \"Park\": [],\n",
    "    \"AM Pattern\": [],\n",
    "    \"PM Pattern\": []\n",
    "}\n",
    "\n",
    "for time in AKpermanent_times:\n",
    "    AKdata[time] = []\n",
    "    \n",
    "# Add AM and PM Patterns\n",
    "for am_pattern, pm_pattern in zip(AKam_patterns, AKpm_patterns):\n",
    "    AKdata[\"OperatingDay\"].append(AKDayOperating)\n",
    "    AKdata[\"Park\"].append(\"AK\")\n",
    "    AKdata[\"AM Pattern\"].append(am_pattern)\n",
    "    AKdata[\"PM Pattern\"].append(pm_pattern)\n",
    "    \n",
    "    for _ in AKpermanent_times:\n",
    "        AKdata[_].append(\"\")\n",
    "# Create DataFrame\n",
    "AKdf = pd.DataFrame(AKdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3528a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMcolumn_time_mapping = {\n",
    "    5: \"5:00\",\n",
    "    6: \"6:00\",\n",
    "    7: \"7:00\",\n",
    "    8: \"8:00\",\n",
    "    9: \"9:00\",\n",
    "    10: \"10:00\", \n",
    "}\n",
    "\n",
    "PMcolumn_time_mapping = {\n",
    "    0: \"24:00\",\n",
    "    1: \"25:00\",\n",
    "    2: \"26:00\",\n",
    "    3: \"27:00\",\n",
    "    11: \"11:00\",\n",
    "    12: \"12:00\",\n",
    "    13: \"13:00\",\n",
    "    14: \"14:00\",\n",
    "    15: \"15:00\",\n",
    "    16: \"16:00\",\n",
    "    17: \"17:00\",\n",
    "    18: \"18:00\",\n",
    "    19: \"19:00\",\n",
    "    20: \"20:00\",\n",
    "    21: \"21:00\",\n",
    "    22: \"22:00\",\n",
    "    23: \"23:00\"\n",
    "}\n",
    "\n",
    "column_time_mapping = {\n",
    "    0: \"24:00\",\n",
    "    1: \"25:00\",\n",
    "    2: \"26:00\",\n",
    "    3: \"27:00\",\n",
    "    5: \"5:00\",\n",
    "    6: \"6:00\",\n",
    "    7: \"7:00\",\n",
    "    8: \"8:00\",\n",
    "    9: \"9:00\",\n",
    "    10: \"10:00\",\n",
    "    11: \"11:00\",\n",
    "    12: \"12:00\",\n",
    "    13: \"13:00\",\n",
    "    14: \"14:00\",\n",
    "    15: \"15:00\",\n",
    "    16: \"16:00\",\n",
    "    17: \"17:00\",\n",
    "    18: \"18:00\",\n",
    "    19: \"19:00\",\n",
    "    20: \"20:00\",\n",
    "    21: \"21:00\",\n",
    "    22: \"22:00\",\n",
    "    23: \"23:00\"\n",
    "}\n",
    "\n",
    "#'AK_KI_JM'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_KI_JM']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[0, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[0, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[0, time_label] = None\n",
    "        \n",
    "#'KI_AK' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['KI_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[1, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[1, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[1, time_label] = None\n",
    "        \n",
    "#'JM_AK' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['JM_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[2, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[2, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[2, time_label] = None\n",
    "        \n",
    "#'AK_PL_GF' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_PL_GF']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[3, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[3, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[3, time_label] = None\n",
    "        \n",
    "#'AK_PL_GF' \n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_PL_GF']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[3, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[3, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[3, time_label] = None\n",
    "        \n",
    "#'PL_AK' \n",
    "#for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    #if column_number in UseAKdf.columns:\n",
    "        #values = [UseAKdf.loc[row, column_number] for row in ['PL_AK']]\n",
    "        #if any(not pd.isna(value) for value in values):\n",
    "            #min_value = np.nanmin(values)\n",
    "            #AKdf.loc[4, time_label] = min_value\n",
    "        #else:\n",
    "            #AKdf.loc[4, time_label] = None\n",
    "    #else:\n",
    "        #AKdf.loc[4, time_label] = None\n",
    "        \n",
    "#'GF_AK' \n",
    "#for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    #if column_number in UseAKdf.columns:\n",
    "        #values = [UseAKdf.loc[row, column_number] for row in ['GF_AK']]\n",
    "        #if any(not pd.isna(value) for value in values):\n",
    "            #min_value = np.nanmin(values)\n",
    "            #AKdf.loc[5, time_label] = min_value\n",
    "        #else:\n",
    "            #AKdf.loc[5, time_label] = None\n",
    "    #else:\n",
    "        #AKdf.loc[5, time_label] = None\n",
    "        \n",
    "#'AK_WL_CO' \n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_WL_CO']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[6, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[6, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[6, time_label] = None\n",
    "        \n",
    "#'WL_AK' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['WL_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[7, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[7, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[7, time_label] = None\n",
    "        \n",
    "#'CO_AK' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['CO_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[8, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[8, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[8, time_label] = None\n",
    "        \n",
    "#'FW-OP_AK', 'AK_FW-OP'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['FW-OP_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[9, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[9, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[9, time_label] = None\n",
    "        \n",
    "#'FW-OP_AK', 'AK_FW-OP'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_FW-OP']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[9, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[9, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[9, time_label] = None\n",
    "        \n",
    "#'AK_YC_BC_BW'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_YC_BC_BW']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[10, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[10, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[10, time_label] = None\n",
    "        \n",
    "#'BC_AK', 'YC_BC_AK'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['BC_AK/YC_BC_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[11, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[11, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[11, time_label] = None\n",
    "        \n",
    "#'BW_AK' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['BW_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[14, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[14, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[14, time_label] = None\n",
    "        \n",
    "#'RV_AK', 'AK_RV'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['RV_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[17, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[17, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[17, time_label] = None\n",
    "        \n",
    "#'RV_AK', 'AK_RV'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_RV']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[17, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[17, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[17, time_label] = None\n",
    "        \n",
    "#'RS-S_AK','RS-WNES-AK', 'AK_WE_NO_EA_SO'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['RS-S_AK/RS-WNES-AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[19, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[19, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[19, time_label] = None\n",
    "        \n",
    "#'RS-S_AK','RS-WNES-AK', 'AK_WE_NO_EA_SO'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_WE_NO_EA_SO']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[19, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[19, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[19, time_label] = None\n",
    "        \n",
    "#'FQ_AK', 'AK_FQ'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['FQ_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[20, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[20, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[20, time_label] = None\n",
    "        \n",
    "#'FQ_AK', 'AK_FQ'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_FQ']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[20, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[20, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[20, time_label] = None\n",
    "        \n",
    "#'AK_JA_MT_RO_TN' \n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_JA_MT_RO_TN']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[21, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[21, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[21, time_label] = None\n",
    "        \n",
    "#'CB-TN_AK', 'MT_TN_AK'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['CB-TN_AK/MT_TN_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[22, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[22, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[22, time_label] = None\n",
    "        \n",
    "#'CB-AB_AK', 'JA_AB_AK'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['CB-AB_AK/JA_AB_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[23, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[23, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[23, time_label] = None\n",
    "        \n",
    "#'EL_AK', 'CA_EL_AK', 'AK_CA_EL'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['EL_AK/CA_EL_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[24, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[24, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[24, time_label] = None\n",
    "        \n",
    "#'EL_AK', 'CA_EL_AK', 'AK_CA_EL'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_CA_EL']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[24, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[24, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[24, time_label] = None\n",
    "        \n",
    "#'KW-HH_AK', 'PN_HH_AK', 'AK_PN_SP_TP_MR_HH'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['KW-HH_AK/PN_HH_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[25, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[25, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[25, time_label] = None\n",
    "        \n",
    "#'KW-HH_AK', 'PN_HH_AK', 'AK_PN_SP_TP_MR_HH'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_PN_SP_TP_MR_HH']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[25, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[25, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[25, time_label] = None\n",
    "        \n",
    "#'SS-SP_AK', 'GS_SP_AK', 'AK_SS'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['SS-SP_AK/GS_SP_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[26, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[26, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[26, time_label] = None\n",
    "        \n",
    "#'SS-SP_AK', 'GS_SP_AK', 'AK_SS'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_SS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[26, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[26, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[26, time_label] = None\n",
    "        \n",
    "#'AS_AK', 'AK_AS'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AS_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[28, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[28, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[28, time_label] = None\n",
    "        \n",
    "#'AS_AK', 'AK_AS'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_AS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[28, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[28, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[28, time_label] = None\n",
    "        \n",
    "#'AM_AK', 'AK_AM' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AM_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[29, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[29, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[29, time_label] = None\n",
    "        \n",
    "#'AM_AK', 'AK_AM' \n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_AM']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[29, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[29, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[29, time_label] = None\n",
    "        \n",
    "#'AV_AK', 'AK_AV'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AV_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[30, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[30, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[30, time_label] = None\n",
    "        \n",
    "#'AV_AK', 'AK_AV'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_AV']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[30, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[30, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[30, time_label] = None\n",
    "        \n",
    "#'PC_AK', 'AK_PC'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['PC_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[31, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[31, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[31, time_label] = None\n",
    "        \n",
    "#'PC_AK', 'AK_PC'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_PC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[31, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[31, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[31, time_label] = None\n",
    "        \n",
    "#'AR_AK', 'AK_AR'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AR_AK']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[32, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[32, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[32, time_label] = None\n",
    "        \n",
    "#'AR_AK', 'AK_AR'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseAKdf.columns:\n",
    "        values = [UseAKdf.loc[row, column_number] for row in ['AK_AR']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            AKdf.loc[32, time_label] = min_value\n",
    "        else:\n",
    "            AKdf.loc[32, time_label] = None\n",
    "    else:\n",
    "        AKdf.loc[32, time_label] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3561415",
   "metadata": {},
   "outputs": [],
   "source": [
    "STam_patterns = [\n",
    "    \"\", \n",
    "    \"KI_ST\",\n",
    "    \"JM_ST\",\n",
    "    \"\",\n",
    "    \"PL_ST\",\n",
    "    \"GF_ST\",\n",
    "    \"\",\n",
    "    \"WL_ST\",\n",
    "    \"CO_ST\",\n",
    "    \"FW-OP_ST\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"SO_ST/WE_SO_ST\",\n",
    "    \"FQ_ST\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"EL_ST/CT_CA_EL_ST\",\n",
    "    \"HH_ST/PN_HH_ST\",\n",
    "    \"SP_ST/GS_SP_ST\",\n",
    "    \"\",\n",
    "    \"AS_ST\",\n",
    "    \"AM_ST\",\n",
    "    \"AV_ST\",\n",
    "    \"\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "# Permanent PM Patterns\n",
    "STpm_patterns = [\n",
    "    \"ST_KI_JM\", \n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"ST_PL_GF\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"ST_WL_CO\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"ST_FW-OP\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"ST_WE_EA_SO\",\n",
    "    \"ST_FQ\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"ST_CA_EL\",\n",
    "    \"ST_PN_HH\",\n",
    "    \"ST_GS_SP\",\n",
    "    \"\",\n",
    "    \"ST_AS\",\n",
    "    \"ST_AM\",\n",
    "    \"ST_AV\",\n",
    "    \"\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "\n",
    "STpermanent_times = [\n",
    "    \"5:00\", \"6:00\", \"7:00\", \"8:00\", \"9:00\", \"10:00\", \"11:00\", \"12:00\",\n",
    "    \"13:00\", \"14:00\", \"15:00\", \"16:00\", \"17:00\", \"18:00\", \"19:00\",\n",
    "    \"20:00\", \"21:00\", \"22:00\", \"23:00\", \"24:00\", \"25:00\", \"26:00\",\n",
    "    \"27:00\"\n",
    "]\n",
    "\n",
    "\n",
    "STdata = {\n",
    "    \"OperatingDay\": [],\n",
    "    \"Park\": [],\n",
    "    \"AM Pattern\": [],\n",
    "    \"PM Pattern\": []\n",
    "}\n",
    "\n",
    "for time in STpermanent_times:\n",
    "    STdata[time] = []\n",
    "    \n",
    "# Add AM and PM Patterns\n",
    "for am_pattern, pm_pattern in zip(STam_patterns, STpm_patterns):\n",
    "    STdata[\"OperatingDay\"].append(STDayOperating)\n",
    "    STdata[\"Park\"].append(\"ST\")\n",
    "    STdata[\"AM Pattern\"].append(am_pattern)\n",
    "    STdata[\"PM Pattern\"].append(pm_pattern)\n",
    "    \n",
    "    for _ in STpermanent_times:\n",
    "        STdata[_].append(\"\")\n",
    "# Create DataFrame\n",
    "STdf = pd.DataFrame(STdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aa0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMcolumn_time_mapping = {\n",
    "    5: \"5:00\",\n",
    "    6: \"6:00\",\n",
    "    7: \"7:00\",\n",
    "    8: \"8:00\",\n",
    "    9: \"9:00\",\n",
    "    10: \"10:00\", \n",
    "}\n",
    "\n",
    "PMcolumn_time_mapping = {\n",
    "    0: \"24:00\",\n",
    "    1: \"25:00\",\n",
    "    2: \"26:00\",\n",
    "    3: \"27:00\",\n",
    "    11: \"11:00\",\n",
    "    12: \"12:00\",\n",
    "    13: \"13:00\",\n",
    "    14: \"14:00\",\n",
    "    15: \"15:00\",\n",
    "    16: \"16:00\",\n",
    "    17: \"17:00\",\n",
    "    18: \"18:00\",\n",
    "    19: \"19:00\",\n",
    "    20: \"20:00\",\n",
    "    21: \"21:00\",\n",
    "    22: \"22:00\",\n",
    "    23: \"23:00\"\n",
    "}\n",
    "\n",
    "column_time_mapping = {\n",
    "    0: \"24:00\",\n",
    "    1: \"25:00\",\n",
    "    2: \"26:00\",\n",
    "    3: \"27:00\",\n",
    "    5: \"5:00\",\n",
    "    6: \"6:00\",\n",
    "    7: \"7:00\",\n",
    "    8: \"8:00\",\n",
    "    9: \"9:00\",\n",
    "    10: \"10:00\",\n",
    "    11: \"11:00\",\n",
    "    12: \"12:00\",\n",
    "    13: \"13:00\",\n",
    "    14: \"14:00\",\n",
    "    15: \"15:00\",\n",
    "    16: \"16:00\",\n",
    "    17: \"17:00\",\n",
    "    18: \"18:00\",\n",
    "    19: \"19:00\",\n",
    "    20: \"20:00\",\n",
    "    21: \"21:00\",\n",
    "    22: \"22:00\",\n",
    "    23: \"23:00\"\n",
    "}\n",
    "\n",
    "#'ST_KI_JM'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['ST_KI_JM']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[0, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[0, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[0, time_label] = None\n",
    "        \n",
    "#'KI_ST' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['KI_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[1, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[1, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[1, time_label] = None\n",
    "        \n",
    "#'JM_ST' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['JM_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[2, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[2, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[2, time_label] = None\n",
    "        \n",
    "#'ST_PL_GF' \n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['ST_PL_GF']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[3, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[3, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[3, time_label] = None\n",
    "        \n",
    "#'PL_ST' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['PL_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[4, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[4, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[4, time_label] = None\n",
    "        \n",
    "#'GF_ST' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['GF_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[5, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[5, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[5, time_label] = None\n",
    "        \n",
    "#'ST_WL_CO' \n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['ST_WL_CO']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[6, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[6, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[6, time_label] = None\n",
    "        \n",
    "#'WL_ST' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['WL_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[7, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[7, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[7, time_label] = None\n",
    "        \n",
    "#'CO_ST' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['CO_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[8, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[8, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[8, time_label] = None\n",
    "        \n",
    "#'FW-OP_ST', 'ST_FW-OP'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['FW-OP_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[9, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[9, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[9, time_label] = None\n",
    "        \n",
    "#'FW-OP_ST', 'ST_FW-OP'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['ST_FW-OP']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[9, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[9, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[9, time_label] = None\n",
    "        \n",
    "#'SO_ST', 'WE_SO_ST', 'ST_WE_EA_SO'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['SO_ST/WE_SO_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[17, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[17, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[17, time_label] = None\n",
    "        \n",
    "#'SO_ST', 'WE_SO_ST', 'ST_WE_EA_SO'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['ST_WE_EA_SO']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[17, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[17, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[17, time_label] = None\n",
    "        \n",
    "#'FQ_ST', 'ST_FQ'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['FQ_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[18, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[18, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[18, time_label] = None\n",
    "        \n",
    "#'FQ_ST', 'ST_FQ'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['ST_FQ']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[18, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[18, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[18, time_label] = None\n",
    "        \n",
    "#'EL_ST', 'CT_CA_EL_ST', 'ST_CA_EL'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['EL_ST/CT_CA_EL_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[22, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[22, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[22, time_label] = None\n",
    "        \n",
    "#'EL_ST', 'CT_CA_EL_ST', 'ST_CA_EL'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['ST_CA_EL']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[22, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[22, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[22, time_label] = None\n",
    "        \n",
    "#'HH_ST', 'PN_HH_ST', 'ST_PN_HH' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['HH_ST/PN_HH_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[23, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[23, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[23, time_label] = None\n",
    "        \n",
    "#'HH_ST', 'PN_HH_ST', 'ST_PN_HH' \n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['ST_PN_HH']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[23, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[23, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[23, time_label] = None\n",
    "        \n",
    "#'SP_ST', 'GS_SP_ST', 'ST_GS_SP'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['SP_ST/GS_SP_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[24, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[24, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[24, time_label] = None\n",
    "        \n",
    "#'SP_ST', 'GS_SP_ST', 'ST_GS_SP'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['ST_GS_SP']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[24, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[24, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[24, time_label] = None\n",
    "        \n",
    "#'AS_ST', 'ST_AS'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['AS_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[26, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[26, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[26, time_label] = None\n",
    "        \n",
    "#'AS_ST', 'ST_AS'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['ST_AS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[26, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[26, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[26, time_label] = None\n",
    "        \n",
    "#'AM_ST', 'ST_AM' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['AM_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[27, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[27, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[27, time_label] = None\n",
    "        \n",
    "#'AM_ST', 'ST_AM' \n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['ST_AM']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[27, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[27, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[27, time_label] = None\n",
    "              \n",
    "#'AV_ST', 'ST_AV' \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['AV_ST']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[28, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[28, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[28, time_label] = None\n",
    "        \n",
    "#'AV_ST', 'ST_AV' \n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseSTdf.columns:\n",
    "        values = [UseSTdf.loc[row, column_number] for row in ['ST_AV']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            STdf.loc[28, time_label] = min_value\n",
    "        else:\n",
    "            STdf.loc[28, time_label] = None\n",
    "    else:\n",
    "        STdf.loc[28, time_label] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECam_patterns = [\n",
    "    \"\", \n",
    "    \"KI_EC\",\n",
    "    \"JM_EC\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"WL_EC\",\n",
    "    \"\",\n",
    "    \"FW-OP_EC\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"SO_EC/WE_SO_EC\",\n",
    "    \"FQ_EC\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"EL_EC/CT_RN_CA_EL_EC\",\n",
    "    \"HH_EC/PN_HH_EC\",\n",
    "    \"SP_EC/GS_SP_EC\",\n",
    "    \"\",\n",
    "    \"AS_EC\",\n",
    "    \"AM_EC\",\n",
    "    \"AV_EC\",\n",
    "    \"\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "# Permanent PM Patterns\n",
    "ECpm_patterns = [\n",
    "    \"EC_KI_JM\", \n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"EC_FW_OP_WL\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"EC_WE_EA_SO\",\n",
    "    \"EC_FQ\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"EC_CA_EL\",\n",
    "    \"EC_PN_SH_HH\",\n",
    "    \"EC_GS_SP\",\n",
    "    \"\",\n",
    "    \"EC_AS\",\n",
    "    \"EC_AM\",\n",
    "    \"EC_AV\",\n",
    "    \"\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "\n",
    "ECpermanent_times = [\n",
    "    \"5:00\", \"6:00\", \"7:00\", \"8:00\", \"9:00\", \"10:00\", \"11:00\", \"12:00\",\n",
    "    \"13:00\", \"14:00\", \"15:00\", \"16:00\", \"17:00\", \"18:00\", \"19:00\",\n",
    "    \"20:00\", \"21:00\", \"22:00\", \"23:00\", \"24:00\", \"25:00\", \"26:00\",\n",
    "    \"27:00\"\n",
    "]\n",
    "\n",
    "\n",
    "ECdata = {\n",
    "    \"OperatingDay\": [],\n",
    "    \"Park\": [],\n",
    "    \"AM Pattern\": [],\n",
    "    \"PM Pattern\": []\n",
    "}\n",
    "\n",
    "for time in ECpermanent_times:\n",
    "    ECdata[time] = []\n",
    "    \n",
    "# Add AM and PM Patterns\n",
    "for am_pattern, pm_pattern in zip(ECam_patterns, ECpm_patterns):\n",
    "    ECdata[\"OperatingDay\"].append(ECDayOperating)\n",
    "    ECdata[\"Park\"].append(\"EC\")\n",
    "    ECdata[\"AM Pattern\"].append(am_pattern)\n",
    "    ECdata[\"PM Pattern\"].append(pm_pattern)\n",
    "    \n",
    "    for _ in ECpermanent_times:\n",
    "        ECdata[_].append(\"\")\n",
    "# Create DataFrame\n",
    "ECdf = pd.DataFrame(ECdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a6d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMcolumn_time_mapping = {\n",
    "    5: \"5:00\",\n",
    "    6: \"6:00\",\n",
    "    7: \"7:00\",\n",
    "    8: \"8:00\",\n",
    "    9: \"9:00\",\n",
    "    10: \"10:00\", \n",
    "}\n",
    "\n",
    "PMcolumn_time_mapping = {\n",
    "    0: \"24:00\",\n",
    "    1: \"25:00\",\n",
    "    2: \"26:00\",\n",
    "    3: \"27:00\",\n",
    "    11: \"11:00\",\n",
    "    12: \"12:00\",\n",
    "    13: \"13:00\",\n",
    "    14: \"14:00\",\n",
    "    15: \"15:00\",\n",
    "    16: \"16:00\",\n",
    "    17: \"17:00\",\n",
    "    18: \"18:00\",\n",
    "    19: \"19:00\",\n",
    "    20: \"20:00\",\n",
    "    21: \"21:00\",\n",
    "    22: \"22:00\",\n",
    "    23: \"23:00\"\n",
    "}\n",
    "\n",
    "column_time_mapping = {\n",
    "    0: \"24:00\",\n",
    "    1: \"25:00\",\n",
    "    2: \"26:00\",\n",
    "    3: \"27:00\",\n",
    "    5: \"5:00\",\n",
    "    6: \"6:00\",\n",
    "    7: \"7:00\",\n",
    "    8: \"8:00\",\n",
    "    9: \"9:00\",\n",
    "    10: \"10:00\",\n",
    "    11: \"11:00\",\n",
    "    12: \"12:00\",\n",
    "    13: \"13:00\",\n",
    "    14: \"14:00\",\n",
    "    15: \"15:00\",\n",
    "    16: \"16:00\",\n",
    "    17: \"17:00\",\n",
    "    18: \"18:00\",\n",
    "    19: \"19:00\",\n",
    "    20: \"20:00\",\n",
    "    21: \"21:00\",\n",
    "    22: \"22:00\",\n",
    "    23: \"23:00\"\n",
    "}\n",
    "\n",
    "#'EC_KI_JM'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['EC_KI_JM']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[0, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[0, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[0, time_label] = None\n",
    "        \n",
    "#'KI_EC'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['KI_EC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[1, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[1, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[1, time_label] = None\n",
    "        \n",
    "#'JM_EC'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['JM_EC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[2, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[2, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[2, time_label] = None\n",
    "        \n",
    "#'EC_FW_OP_WL'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['EC_FW_OP_WL']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[5, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[5, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[5, time_label] = None\n",
    "        \n",
    "#'WL_EC'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['WL_EC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[6, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[6, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[6, time_label] = None\n",
    "        \n",
    "#'FW-OP_EC'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['FW-OP_EC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[8, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[8, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[8, time_label] = None\n",
    "        \n",
    "#'SO_EC', 'WE_SO_EC', 'EC_WE_EA_SO'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['SO_EC/WE_SO_EC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[16, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[16, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[16, time_label] = None\n",
    "        \n",
    "#'SO_EC', 'WE_SO_EC', 'EC_WE_EA_SO'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['EC_WE_EA_SO']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[16, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[16, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[16, time_label] = None\n",
    "        \n",
    "#'FQ_EC', 'EC_FQ'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['FQ_EC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[17, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[17, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[17, time_label] = None\n",
    "        \n",
    "#'FQ_EC', 'EC_FQ'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['EC_FQ']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[17, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[17, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[17, time_label] = None\n",
    "        \n",
    "#'EL_EC', 'CT_RN_CA_EL_EC', 'EC_CA_EL'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['EL_EC/CT_RN_CA_EL_EC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[21, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[21, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[21, time_label] = None\n",
    "        \n",
    "#'EL_EC', 'CT_RN_CA_EL_EC', 'EC_CA_EL'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['EC_CA_EL']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[21, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[21, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[21, time_label] = None\n",
    "        \n",
    "#'HH_EC', 'PN_HH_EC', 'EC_PN_SH_HH'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['HH_EC/PN_HH_EC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[22, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[22, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[22, time_label] = None\n",
    "        \n",
    "#'HH_EC', 'PN_HH_EC', 'EC_PN_SH_HH'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['EC_PN_SH_HH']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[22, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[22, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[22, time_label] = None\n",
    "        \n",
    "#'SP_EC', 'GS_SP_EC', 'EC_GS_SP'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['SP_EC/GS_SP_EC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[23, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[23, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[23, time_label] = None\n",
    "        \n",
    "#'SP_EC', 'GS_SP_EC', 'EC_GS_SP'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['EC_GS_SP']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[23, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[23, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[23, time_label] = None\n",
    "        \n",
    "#'AS_EC', 'EC_AS'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['AS_EC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[25, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[25, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[25, time_label] = None\n",
    "        \n",
    "#'AS_EC', 'EC_AS'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['EC_AS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[25, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[25, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[25, time_label] = None\n",
    "        \n",
    "#'AM_EC', 'EC_AM'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['AM_EC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[26, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[26, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[26, time_label] = None\n",
    "        \n",
    "#'AM_EC', 'EC_AM'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['EC_AM']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[26, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[26, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[26, time_label] = None\n",
    "\n",
    "        \n",
    "#'AV_EC', 'EC_AV'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['AV_EC']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[27, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[27, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[27, time_label] = None\n",
    "        \n",
    "#'AV_EC', 'EC_AV'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseECdf.columns:\n",
    "        values = [UseECdf.loc[row, column_number] for row in ['EC_AV']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            ECdf.loc[27, time_label] = min_value\n",
    "        else:\n",
    "            ECdf.loc[27, time_label] = None\n",
    "    else:\n",
    "        ECdf.loc[27, time_label] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae1a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DSam_patterns = [\n",
    "    \"KI_DS/JM_KI_DS\", \n",
    "    \"\", \n",
    "    \"GF_DS/PL_GF_DS\", \n",
    "    \"\", \"\", \n",
    "    \"CO_DS/WL_CO_DS\", \n",
    "    \"\", \"\", \n",
    "    \"FW-OP_DS\", \n",
    "    \"BW_DS/YC_BC_BW_DS\", \n",
    "    \"\", \"\", \"\", \"\", \"\", \n",
    "    \"RV_DS\", \"FQ_DS\", \n",
    "    \"\", \"\",\n",
    "    \"AB_DS/MT_RO_AB_DS\", \n",
    "    \"CA_DS/EL_CT_CA_DS\", \"MR_DS/HH_PI_SP_TP_MR_DS\", \"CP_DS/SP_GD_CS_PD_CP_DS\",\n",
    "    \"\",\n",
    "    \"AV_DS\", \"AS_DS\", \"AM_DS\", \"PC_DS_NEW\", \"AR_DS\"\n",
    "]\n",
    "\n",
    "# Permanent PM Patterns\n",
    "DSpm_patterns = [\n",
    "    \"DS_JM_KI\", \n",
    "    \"\", \n",
    "    \"DS_PL_GF\", \n",
    "    \"\", \"\", \n",
    "    \"DS_WL_CO\", \n",
    "    \"\", \"\", \n",
    "    \"DS_FW-OP\", \"DS_YC_BC_BW\",\n",
    "    \"\", \"\", \"\", \"\", \"\",\n",
    "    \"DS_RV\", \"DS_FQ_RS-SWNE_FQ\", \n",
    "    \"\", \"\",\n",
    "    \"DS_TN_AB\", \"DS_EL_CA\", \"DS_HH_MR\",\n",
    "    \"DS_SP_CP\", \n",
    "    \"\",\n",
    "    \"DS_AV\", \"DS_AS\", \"DS_AM\", \"DS_PC_NEW\", \"DS_AR\"\n",
    "]\n",
    "\n",
    "\n",
    "DSpermanent_times = [\n",
    "    \"5:00\", \"6:00\", \"7:00\", \"8:00\", \"9:00\", \"10:00\", \"11:00\", \"12:00\",\n",
    "    \"13:00\", \"14:00\", \"15:00\", \"16:00\", \"17:00\", \"18:00\", \"19:00\",\n",
    "    \"20:00\", \"21:00\", \"22:00\", \"23:00\", \"24:00\", \"25:00\", \"26:00\",\n",
    "    \"27:00\"\n",
    "]\n",
    "\n",
    "\n",
    "DSdata = {\n",
    "    \"OperatingDay\": [],\n",
    "    \"Park\": [],\n",
    "    \"AM Pattern\": [],\n",
    "    \"PM Pattern\": []\n",
    "}\n",
    "\n",
    "for time in DSpermanent_times:\n",
    "    DSdata[time] = []\n",
    "    \n",
    "# Add AM and PM Patterns\n",
    "for am_pattern, pm_pattern in zip(DSam_patterns, DSpm_patterns):\n",
    "    DSdata[\"OperatingDay\"].append(DSDayOperating)\n",
    "    DSdata[\"Park\"].append(\"DS\")\n",
    "    DSdata[\"AM Pattern\"].append(am_pattern)\n",
    "    DSdata[\"PM Pattern\"].append(pm_pattern)\n",
    "    \n",
    "    for _ in DSpermanent_times:\n",
    "        DSdata[_].append(\"\")\n",
    "# Create DataFrame\n",
    "DSdf = pd.DataFrame(DSdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029939ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMcolumn_time_mapping = {\n",
    "    5: \"5:00\",\n",
    "    6: \"6:00\",\n",
    "    7: \"7:00\",\n",
    "    8: \"8:00\",\n",
    "    9: \"9:00\",\n",
    "    10: \"10:00\", \n",
    "}\n",
    "\n",
    "PMcolumn_time_mapping = {\n",
    "    0: \"24:00\",\n",
    "    1: \"25:00\",\n",
    "    2: \"26:00\",\n",
    "    3: \"27:00\",\n",
    "    11: \"11:00\",\n",
    "    12: \"12:00\",\n",
    "    13: \"13:00\",\n",
    "    14: \"14:00\",\n",
    "    15: \"15:00\",\n",
    "    16: \"16:00\",\n",
    "    17: \"17:00\",\n",
    "    18: \"18:00\",\n",
    "    19: \"19:00\",\n",
    "    20: \"20:00\",\n",
    "    21: \"21:00\",\n",
    "    22: \"22:00\",\n",
    "    23: \"23:00\"\n",
    "}\n",
    "\n",
    "column_time_mapping = {\n",
    "    0: \"24:00\",\n",
    "    1: \"25:00\",\n",
    "    2: \"26:00\",\n",
    "    3: \"27:00\",\n",
    "    5: \"5:00\",\n",
    "    6: \"6:00\",\n",
    "    7: \"7:00\",\n",
    "    8: \"8:00\",\n",
    "    9: \"9:00\",\n",
    "    10: \"10:00\",\n",
    "    11: \"11:00\",\n",
    "    12: \"12:00\",\n",
    "    13: \"13:00\",\n",
    "    14: \"14:00\",\n",
    "    15: \"15:00\",\n",
    "    16: \"16:00\",\n",
    "    17: \"17:00\",\n",
    "    18: \"18:00\",\n",
    "    19: \"19:00\",\n",
    "    20: \"20:00\",\n",
    "    21: \"21:00\",\n",
    "    22: \"22:00\",\n",
    "    23: \"23:00\"\n",
    "}\n",
    "\n",
    "#'KI_DS', 'JM_KI_DS', 'DS_JM_KI'      \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['KI_DS/JM_KI_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[0, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[0, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[0, time_label] = None\n",
    "        \n",
    "#'KI_DS', 'JM_KI_DS', 'DS_JM_KI'      \n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_JM_KI']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[0, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[0, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[0, time_label] = None\n",
    "        \n",
    "#'GF_DS', 'PL_GF_DS', 'DS_PL_GF'        \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['GF_DS/PL_GF_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[2, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[2, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[2, time_label] = None\n",
    "        \n",
    "#'GF_DS', 'PL_GF_DS', 'DS_PL_GF'        \n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_PL_GF']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[2, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[2, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[2, time_label] = None\n",
    "        \n",
    "#'CO_DS', 'WL_CO_DS', 'DS_WL_CO'       \n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['CO_DS/WL_CO_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[5, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[5, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[5, time_label] = None\n",
    "        \n",
    "#'CO_DS', 'WL_CO_DS', 'DS_WL_CO'       \n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_WL_CO']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[5, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[5, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[5, time_label] = None\n",
    "        \n",
    "#'FW-OP_DS', 'DS_FW-OP'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['FW-OP_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[8, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[8, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[8, time_label] = None\n",
    "        \n",
    "#'FW-OP_DS', 'DS_FW-OP'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_FW-OP']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[8, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[8, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[8, time_label] = None\n",
    "        \n",
    "#'BW_DS','YC_BC_BW_DS', 'DS_YC_BC_BW'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['BW_DS/YC_BC_BW_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[9, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[9, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[9, time_label] = None\n",
    "        \n",
    "#'BW_DS','YC_BC_BW_DS', 'DS_YC_BC_BW'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_YC_BC_BW']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[9, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[9, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[9, time_label] = None\n",
    "        \n",
    "#'RV_DS', 'DS_RV'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['RV_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[15, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[15, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[15, time_label] = None\n",
    "        \n",
    "#'RV_DS', 'DS_RV'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_RV']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[15, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[15, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[15, time_label] = None\n",
    "        \n",
    "#'FQ_DS', 'DS_FQ_RS-SWNE_FQ'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['FQ_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[16, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[16, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[16, time_label] = None\n",
    "        \n",
    "#'FQ_DS', 'DS_FQ_RS-SWNE_FQ'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_FQ_RS-SWNE_FQ']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[16, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[16, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[16, time_label] = None\n",
    "        \n",
    "#'AB_DS', 'MT_RO_AB_DS', 'DS_TN_AB'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['AB_DS/MT_RO_AB_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[19, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[19, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[19, time_label] = None\n",
    "        \n",
    "#'AB_DS', 'MT_RO_AB_DS', 'DS_TN_AB'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_TN_AB']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[19, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[19, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[19, time_label] = None\n",
    "        \n",
    "#'CA_DS', 'EL_CT_CA_DS', 'DS_EL_CA'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['CA_DS/EL_CT_CA_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[20, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[20, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[20, time_label] = None\n",
    "        \n",
    "#'CA_DS', 'EL_CT_CA_DS', 'DS_EL_CA'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_EL_CA']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[20, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[20, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[20, time_label] = None\n",
    "        \n",
    "#'MR_DS', 'HH_PI_SP_TP_MR_DS', 'DS_HH_MR'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['MR_DS/HH_PI_SP_TP_MR_DS', 'DS_HH_MR']]\n",
    "        \n",
    "        numeric_values = [value for value in values if not pd.isna(value) and (isinstance(value, (float, int)))]\n",
    "        timestamp_values = [value for value in values if not pd.isna(value) and isinstance(value, pd.Timestamp)]\n",
    "        \n",
    "        if timestamp_values:\n",
    "            min_timestamp = min(timestamp_values)\n",
    "            hour = min_timestamp.hour\n",
    "            minute = min_timestamp.minute\n",
    "            second = min_timestamp.second\n",
    "            combined_datetime = datetime(1900, 1, 1, hour, minute, second)\n",
    "            formatted_datetime = combined_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            DSdf.loc[21, time_label] = formatted_datetime\n",
    "        elif numeric_values:\n",
    "            min_value = min(numeric_values)\n",
    "            DSdf.loc[21, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[21, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[21, time_label] = None\n",
    "        \n",
    "#'MR_DS', 'HH_PI_SP_TP_MR_DS', 'DS_HH_MR'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_HH_MR']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[21, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[21, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[21, time_label] = None\n",
    "        \n",
    "#'CP_DS', 'SP_GD_CS_PD_CP_DS', 'DS_SP_CP'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['CP_DS/SP_GD_CS_PD_CP_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[22, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[22, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[22, time_label] = None\n",
    "        \n",
    "#'CP_DS', 'SP_GD_CS_PD_CP_DS', 'DS_SP_CP'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_SP_CP']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[22, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[22, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[22, time_label] = None\n",
    "        \n",
    "#'AV_DS', 'DS_AV'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['AV_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[24, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[24, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[24, time_label] = None\n",
    "        \n",
    "#'AV_DS', 'DS_AV'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_AV']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[24, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[24, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[24, time_label] = None\n",
    "        \n",
    "#'AS_DS', 'DS_AS'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['AS_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[25, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[25, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[25, time_label] = None\n",
    "        \n",
    "#'AS_DS', 'DS_AS'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_AS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[25, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[25, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[25, time_label] = None\n",
    "        \n",
    "#'AM_DS', 'DS_AM'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['AM_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[26, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[26, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[26, time_label] = None\n",
    "        \n",
    "#'AM_DS', 'DS_AM'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_AM']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[26, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[26, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[26, time_label] = None\n",
    "        \n",
    "#'PC_DS_NEW', 'DS_PC_NEW'\n",
    "for column_number, time_label in AMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['PC_DS_NEW']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[27, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[27, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[27, time_label] = None\n",
    "        \n",
    "#'PC_DS_NEW', 'DS_PC_NEW'\n",
    "for column_number, time_label in PMcolumn_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_PC_NEW']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[27, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[27, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[27, time_label] = None\n",
    "        \n",
    "#'AR_DS', 'DS_AR'\n",
    "for column_number, time_label in column_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['AR_DS']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[28, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[28, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[28, time_label] = None\n",
    "        \n",
    "#'AR_DS', 'DS_AR'\n",
    "for column_number, time_label in column_time_mapping.items():\n",
    "    if column_number in UseDSdf.columns:\n",
    "        values = [UseDSdf.loc[row, column_number] for row in ['DS_AR']]\n",
    "        if any(not pd.isna(value) for value in values):\n",
    "            min_value = np.nanmin(values)\n",
    "            DSdf.loc[28, time_label] = min_value\n",
    "        else:\n",
    "            DSdf.loc[28, time_label] = None\n",
    "    else:\n",
    "        DSdf.loc[28, time_label] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b3ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [MKdf, AKdf, STdf, ECdf, DSdf]\n",
    "\n",
    "# Concatenate the DataFrames vertically\n",
    "FINALDF = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf1de7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def custom_round(num):\n",
    "    if isinstance(num, (int, float)):  # Check if value is numeric\n",
    "        if num > 0.5:\n",
    "            return int(num)\n",
    "        else:\n",
    "            return int(num) + 1\n",
    "    else:\n",
    "        return num  # Return string values unchanged\n",
    "\n",
    "# Apply custom rounding function to all columns\n",
    "FINALDF = FINALDF.applymap(custom_round)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "FINALDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df43b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINALDF.to_csv('Z:/Logistics/Nick Gdula/Option3PlannedHeadway10-7.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
